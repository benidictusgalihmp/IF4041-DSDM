{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-04T08:32:20.098984Z","iopub.execute_input":"2022-12-04T08:32:20.099366Z","iopub.status.idle":"2022-12-04T08:32:20.111895Z","shell.execute_reply.started":"2022-12-04T08:32:20.099334Z","shell.execute_reply":"2022-12-04T08:32:20.110638Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/domesticusairflight2016-2018/combine_files.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from copy import deepcopy\nimport json ","metadata":{"execution":{"iopub.status.busy":"2022-12-04T08:32:20.114589Z","iopub.execute_input":"2022-12-04T08:32:20.115254Z","iopub.status.idle":"2022-12-04T08:32:20.120282Z","shell.execute_reply.started":"2022-12-04T08:32:20.115219Z","shell.execute_reply":"2022-12-04T08:32:20.118738Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"raw = pd.read_csv(\"/kaggle/input/domesticusairflight2016-2018/combine_files.csv\", \n                  keep_default_na=False,\n                  usecols=['Year',\n                           'Origin',\n                           'Dest',\n                           'ActualElapsedTime'\n                          ])","metadata":{"execution":{"iopub.status.busy":"2022-12-04T08:32:20.152301Z","iopub.execute_input":"2022-12-04T08:32:20.152978Z","iopub.status.idle":"2022-12-04T08:32:53.262908Z","shell.execute_reply.started":"2022-12-04T08:32:20.152938Z","shell.execute_reply":"2022-12-04T08:32:53.261565Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df = deepcopy(raw)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T08:32:53.265309Z","iopub.execute_input":"2022-12-04T08:32:53.265766Z","iopub.status.idle":"2022-12-04T08:32:53.670384Z","shell.execute_reply.started":"2022-12-04T08:32:53.265724Z","shell.execute_reply":"2022-12-04T08:32:53.669074Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   Year ActualElapsedTime Origin Dest\n0  2016             155.0    DFW  DTW\n1  2016             150.0    DFW  DTW\n2  2016             170.0    DFW  DTW\n3  2016             151.0    DFW  DTW\n4  2016             171.0    DFW  DTW","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>ActualElapsedTime</th>\n      <th>Origin</th>\n      <th>Dest</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016</td>\n      <td>155.0</td>\n      <td>DFW</td>\n      <td>DTW</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016</td>\n      <td>150.0</td>\n      <td>DFW</td>\n      <td>DTW</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016</td>\n      <td>170.0</td>\n      <td>DFW</td>\n      <td>DTW</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016</td>\n      <td>151.0</td>\n      <td>DFW</td>\n      <td>DTW</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016</td>\n      <td>171.0</td>\n      <td>DFW</td>\n      <td>DTW</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_remain = df.sample(frac = 0.00006)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T09:31:51.850257Z","iopub.execute_input":"2022-12-04T09:31:51.850855Z","iopub.status.idle":"2022-12-04T09:31:53.202637Z","shell.execute_reply.started":"2022-12-04T09:31:51.850812Z","shell.execute_reply":"2022-12-04T09:31:53.201572Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"df_remain.info()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T09:31:53.204765Z","iopub.execute_input":"2022-12-04T09:31:53.205182Z","iopub.status.idle":"2022-12-04T09:31:53.227889Z","shell.execute_reply.started":"2022-12-04T09:31:53.205147Z","shell.execute_reply":"2022-12-04T09:31:53.225941Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 1110 entries, 5684737 to 3692731\nData columns (total 4 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   Year               1110 non-null   int64 \n 1   ActualElapsedTime  1110 non-null   object\n 2   Origin             1110 non-null   object\n 3   Dest               1110 non-null   object\ndtypes: int64(1), object(3)\nmemory usage: 43.4+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"years = [2016, 2017, 2018]\ndictionary = dict()\n\nfor year in years:\n    dictionary[year] = {\n        'origin': df_remain[df_remain['Year'] == year]['Origin'].to_numpy(),\n        'dest': df_remain[df_remain['Year'] == year]['Dest'].to_numpy(),\n        'origin_u': df_remain[df_remain['Year'] == year]['Origin'].unique(),\n        'dest_u': df_remain[df_remain['Year'] == year]['Dest'].unique(),\n        'actualtime': df_remain[df_remain['Year'] == year]['ActualElapsedTime'].to_numpy(),\n    }","metadata":{"execution":{"iopub.status.busy":"2022-12-04T09:31:53.230886Z","iopub.execute_input":"2022-12-04T09:31:53.231445Z","iopub.status.idle":"2022-12-04T09:31:53.272704Z","shell.execute_reply.started":"2022-12-04T09:31:53.231397Z","shell.execute_reply":"2022-12-04T09:31:53.269851Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# 'origin': df[df['Year'] == year]['Origin'].to_numpy(),\n#         'dest': df[df['Year'] == year]['Dest'].to_numpy(),\n#         'origin_u': df[df['Year'] == year]['Origin'].unique(),\n#         'dest_u': df[df['Year'] == year]['Dest'].unique(),\n#         'distance': df[df['Year'] == year]['Distance'].to_numpy(),\n\n# create new json file foreach year\nfor year in dictionary:\n    origins = dictionary[year]['origin']\n    destinations = dictionary[year]['dest']\n    origin_unique = dictionary[year]['origin_u']\n    dest_unique = dictionary[year]['dest_u']\n    actualtimes = dictionary[year]['actualtime']\n    cities = np.unique(np.concatenate((origin_unique, dest_unique),0))\n    \n    jsonfile = dict()\n    \n    # create nodes dictionary\n    nodes = []\n\n    for city in cities:\n        nodes.append(\n            {\"name\": city}\n        )\n    \n    # create links dictionary\n    links = []\n    temp = None\n\n    for origin, dest, timelength in zip(origins, destinations, actualtimes):\n        if(temp != (origin, dest)):\n            links.append(\n                {\"source\": origin, \"target\": dest, \"actualtime\": timelength}\n            )\n            temp = (origin, dest)\n            \n    jsonfile[\"nodes\"] = nodes\n    jsonfile[\"links\"] = links\n    \n    filename = str(year) + \".json\"\n    with open(filename, \"w\") as outfile:\n        json.dump(jsonfile, outfile)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T09:31:53.276130Z","iopub.execute_input":"2022-12-04T09:31:53.276645Z","iopub.status.idle":"2022-12-04T09:31:53.309249Z","shell.execute_reply.started":"2022-12-04T09:31:53.276601Z","shell.execute_reply":"2022-12-04T09:31:53.307647Z"},"trusted":true},"execution_count":50,"outputs":[]}]}